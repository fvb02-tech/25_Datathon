# PolicyPulse ğŸ“Š

**Analyseur d'Impact RÃ©glementaire en Temps RÃ©el pour les Entreprises du S&P 500**

[![AWS Bedrock](https://img.shields.io/badge/AWS-Bedrock-orange)](https://aws.amazon.com/bedrock/)
[![Claude AI](https://img.shields.io/badge/Claude-Sonnet%203.5-blue)](https://www.anthropic.com/claude)
[![Python](https://img.shields.io/badge/Python-3.8+-green)](https://www.python.org/)
[![Dash](https://img.shields.io/badge/Framework-Dash-lightblue)](https://dash.plotly.com/)

---

## ğŸ† Datathon PolyFinances 2025

Projet dÃ©veloppÃ© dans le cadre du **Datathon PolyFinances 2025** par l'**Ã‰quipe 25**.

### ğŸ¯ Mission

CrÃ©er un systÃ¨me intelligent capable d'Ã©valuer automatiquement l'impact de nouvelles rÃ©glementations sur les entreprises du S&P 500 en combinant:
- **Analyse de documents rÃ©glementaires** (lois, directives, dÃ©crets)
- **Extraction de donnÃ©es financiÃ¨res** depuis les rapports 10-K
- **Intelligence artificielle** via AWS Bedrock et Claude Sonnet
- **Visualisations interactives** pour la prise de dÃ©cision

---

## ğŸš€ FonctionnalitÃ©s

### ğŸ“¤ Upload et Parsing de Documents
- Support multi-format: **HTML, XML, PDF, TXT**
- Validation automatique des documents rÃ©glementaires
- Extraction intelligente du contenu pertinent
- DÃ©tection de mots-clÃ©s multilingues (FR, EN, ZH, ES, DE)

### ğŸ¤– Analyse d'Impact par IA
- **ModÃ¨le**: Claude 3.5 Sonnet via AWS Bedrock
- **Scoring**: Ã‰chelle de -3 (impact trÃ¨s nÃ©gatif) Ã  +3 (trÃ¨s positif)
- **Analyse contextuelle**: Croisement rÃ©glementation Ã— profil entreprise
- Traitement parallÃ¨le de **50 entreprises simultanÃ©ment**

### ğŸ“Š Dashboard Interactif
- **Visualisations par secteur**: Graphiques en barres et scatter plots
- **Vue par entreprise**: Filtrage et recherche avancÃ©e
- **Export de donnÃ©es**: CSV et PDF
- **Mode hors-ligne**: Simulation si Bedrock indisponible

### ğŸ“ˆ Exploitation des DonnÃ©es 10-K
- Extraction automatique des **500 entreprises du S&P 500**
- Analyse des profils:
  - Exposition gÃ©ographique
  - Mix d'activitÃ©s
  - ChaÃ®nes d'approvisionnement
  - DÃ©penses R&D
  - MÃ©triques financiÃ¨res

---

## ğŸ—ï¸ Architecture Technique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Document        â”‚
â”‚ RÃ©glementaire   â”‚ (HTML/XML/PDF/TXT)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Parser Module   â”‚ (extraction_mod)
â”‚ Multi-format    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AWS Bedrock     â”‚ (Claude 3.5 Sonnet)
â”‚ Analyse Impact  â”‚ Ã— 500 entreprises
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Dash Dashboard  â”‚ (Visualisations)
â”‚ Interface Web   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technologies UtilisÃ©es

| CatÃ©gorie | Technologies |
|-----------|-------------|
| **IA** | AWS Bedrock, Claude 3.5 Sonnet |
| **Backend** | Python 3.8+, Boto3 |
| **Frontend** | Dash 2.14, Plotly 5.18, Bootstrap |
| **Data Processing** | Pandas, NumPy |
| **Parsing** | BeautifulSoup4, lxml, PyMuPDF |
| **DÃ©ploiement** | Gunicorn, SageMaker |

---

## ğŸ“ Structure du Projet

```
regulatory_impact_analyzer/
â”‚
â”œâ”€â”€ ğŸ“Š dashboard/               # Interface web Dash
â”‚   â”œâ”€â”€ app.py                  # Application principale
â”‚   â”œâ”€â”€ regulatory_utils.py    # Utilitaires d'analyse
â”‚   â”œâ”€â”€ config.py               # Configuration (Bedrock, chemins)
â”‚   â””â”€â”€ requirements.txt        # DÃ©pendances dashboard
â”‚
â”œâ”€â”€ ğŸ“„ extraction_mod/          # Extraction de documents 10-K
â”‚   â”œâ”€â”€ extract_10k.py          # Version 1 - Extraction basique
â”‚   â””â”€â”€ extract_10k_v2.py       # Version 2 - Extraction avancÃ©e
â”‚
â”œâ”€â”€ ğŸ““ notebooks/               # Analyses exploratoires
â”‚   â”œâ”€â”€ 01_exploration_donnees.ipynb   # Exploration S&P 500
â”‚   â”œâ”€â”€ 02_parse_documents.ipynb       # Tests de parsing
â”‚   â”œâ”€â”€ 03_parse_rapport10k.ipynb      # Extraction 10-K
â”‚   â””â”€â”€ 04_bedrock_analysis.ipynb      # Tests Bedrock
â”‚
â”œâ”€â”€ ğŸ”§ app/                     # Scripts d'analyse
â”‚   â””â”€â”€ run_analysis.py         # Pipeline complet d'analyse
â”‚
â”œâ”€â”€ ğŸ“¦ data/
â”‚   â””â”€â”€ processed/              # DonnÃ©es nettoyÃ©es
â”‚       â”œâ”€â”€ sp500_cleaned.csv           # Liste S&P 500
â”‚       â”œâ”€â”€ company_10k_data*.json      # Profils entreprises
â”‚       â””â”€â”€ regulatory_documents.json   # Documents analysÃ©s
â”‚
â”œâ”€â”€ config.py                   # Configuration globale
â””â”€â”€ README.md                   # Documentation
```

---

## âš™ï¸ Installation

### PrÃ©requis

- **Python 3.8+**
- **Compte AWS** avec accÃ¨s Ã  Bedrock
- **Credentials AWS** configurÃ©s

### Installation des dÃ©pendances

```bash
# Cloner le dÃ©pÃ´t
git clone <repo_url>
cd 25_Datathon/regulatory_impact_analyzer

# Installer les dÃ©pendances dashboard
cd dashboard
pip install -r requirements.txt

# DÃ©pendances systÃ¨me (optionnelles pour PDF)
sudo apt-get install libcairo2-dev libpango1.0-dev
pip install reportlab weasyprint
```

### Configuration AWS

CrÃ©er un fichier `.env` Ã  la racine du projet:

```bash
# Chemins de donnÃ©es
PROJECT_DIR=/home/user/25_Datathon/regulatory_impact_analyzer
PROCESSED_DIR=/home/user/25_Datathon/regulatory_impact_analyzer/data/processed
FILLINGS_DIR=/path/to/your/10k/fillings
DIRECTIVE_DIR=/path/to/your/directives

# AWS Bedrock
AWS_REGION=us-west-2
BEDROCK_MODEL_ID=anthropic.claude-3-5-sonnet-20241022-v2:0
K_MODEL=anthropic.claude-3-5-sonnet-20241022-v2:0
```

### Configuration AWS CLI

```bash
aws configure
# Entrer:
# - AWS Access Key ID
# - AWS Secret Access Key
# - Region: us-west-2
# - Format: json
```

---

## ğŸ® Utilisation

### 1. Lancement du Dashboard

```bash
cd dashboard
python app.py
```

Le dashboard sera accessible sur: **http://localhost:8050**

### 2. Upload d'un Document RÃ©glementaire

1. **Glisser-dÃ©poser** ou **cliquer** sur la zone d'upload
2. SÃ©lectionner un fichier `.html`, `.xml`, `.pdf` ou `.txt`
3. Le systÃ¨me valide automatiquement le document
4. L'analyse dÃ©marre immÃ©diatement

### 3. Consultation des RÃ©sultats

#### Vue par Secteur
- Graphique en **barres**: Score moyen par secteur
- **Scatter plot**: Distribution des entreprises
- **Filtrage**: SÃ©lectionner un secteur pour dÃ©tails

#### Vue par Entreprise
- **Tableau dÃ©taillÃ©**: 500 entreprises avec scores
- **Recherche**: Par nom ou ticker
- **Tri**: Par impact, secteur, fiabilitÃ©

### 4. Export des DonnÃ©es

- **CSV**: TÃ©lÃ©charger les rÃ©sultats complets
- **PDF**: GÃ©nÃ©rer un rapport formatÃ© (nÃ©cessite reportlab)

---

## ğŸ”¬ Pipeline d'Analyse

### Ã‰tape 1: Extraction 10-K

```bash
cd app
python run_analysis.py
```

**Processus**:
1. TÃ©lÃ©chargement des 10-K depuis EDGAR
2. Extraction des sections clÃ©s (Business, Risk Factors, MD&A)
3. Structuration en profils JSON

### Ã‰tape 2: Analyse d'Impact

Pour chaque entreprise, le systÃ¨me:

1. **Charge le profil 10-K**
   - Secteur, gÃ©ographie, business mix
   - Supply chain, R&D

2. **Construit le prompt Bedrock**
   ```
   REGULATION: [requirements extracted]
   COMPANY: [10-K profile]
   TASK: Evaluate impact and return JSON score
   ```

3. **Appelle Claude Sonnet**
   - Analyse contextuelle
   - GÃ©nÃ©ration du score (-3 Ã  +3)
   - Justifications et explications

4. **AgrÃ¨ge les rÃ©sultats**
   - Calcul des moyennes par secteur
   - Statistiques de fiabilitÃ©
   - Sauvegarde JSON

### Ã‰tape 3: Visualisation

Le dashboard charge les rÃ©sultats et gÃ©nÃ¨re:
- Graphiques interactifs
- Tables filtrables
- Exports personnalisÃ©s

---

## ğŸ““ Notebooks Jupyter

### `01_exploration_donnees.ipynb`
- Chargement de la liste S&P 500
- Statistiques par secteur
- Visualisations initiales

### `02_parse_documents.ipynb`
- Tests de parsing HTML/XML
- Extraction de contenu rÃ©glementaire
- Validation de formats

### `03_parse_rapport10k.ipynb`
- Tests d'extraction 10-K
- Structuration des donnÃ©es
- Nettoyage et transformation

### `04_bedrock_analysis.ipynb`
- Appels API Bedrock
- Tests de prompts
- Analyse de rÃ©ponses

---

## ğŸ¨ FonctionnalitÃ©s AvancÃ©es

### Mode Simulation

Si AWS Bedrock n'est pas disponible, le systÃ¨me gÃ©nÃ¨re des scores alÃ©atoires rÃ©alistes pour la dÃ©monstration:

```python
BEDROCK_AVAILABLE = False  # Bascule en mode simulation
```

### Traitement ParallÃ¨le

Analyse de **50 entreprises simultanÃ©ment** via `ThreadPoolExecutor`:

```python
MAX_WORKERS = 50  # Configurable dans config.py
```

### Validation Multilingue

DÃ©tection de documents rÃ©glementaires en **5 langues**:
- FranÃ§ais, Anglais, Chinois, Espagnol, Allemand

### Gestion d'Erreurs

- **Retry automatique** (2 tentatives) sur Ã©checs Bedrock
- **Logs dÃ©taillÃ©s** avec timestamps
- **Fallback gracieux** en mode simulation

---

## ğŸ“Š Exemples de RÃ©sultats

### Analyse d'une Directive Environnementale

**Document**: Directive EU Carbon Pricing 2025

| Secteur | Score Moyen | Entreprises ImpactÃ©es |
|---------|-------------|----------------------|
| Energy | -2.1 | 28 entreprises |
| Utilities | -1.8 | 31 entreprises |
| Industrials | -0.9 | 72 entreprises |
| Technology | +0.3 | 68 entreprises |
| Financials | +0.5 | 65 entreprises |

**Insights**:
- Secteurs fossiles fortement impactÃ©s nÃ©gativement
- Tech et finance bÃ©nÃ©ficient de nouvelles opportunitÃ©s
- 127 entreprises nÃ©cessitent adaptations majeures

---

## ğŸ”§ Configuration AvancÃ©e

### Personnalisation des Prompts

Modifier `IMPACT_ANALYSIS_PROMPT` dans `dashboard/app.py`:

```python
IMPACT_ANALYSIS_PROMPT = """
Your custom prompt here...
- Modify scoring criteria
- Add specific analysis dimensions
- Customize output format
"""
```

### Ajustement des Seuils

Dans `dashboard/config.py`:

```python
MIN_DOCUMENT_LENGTH = 50      # Longueur min document
MIN_KEYWORD_MATCHES = 1       # Mots-clÃ©s min requis
MAX_WORKERS = 50              # ParallÃ©lisme
```

### Chemins de DonnÃ©es PersonnalisÃ©s

Dans `.env`:

```bash
PROCESSED_DIR=/custom/path/to/data
FILLINGS_DIR=/custom/path/to/10k
```

---

## ğŸš€ DÃ©ploiement

### DÃ©ploiement Local

```bash
cd dashboard
gunicorn app:server -b 0.0.0.0:8050
```

### DÃ©ploiement SageMaker

```bash
# Configurer SageMaker Studio
# Monter le filesystem S3
# Lancer l'application avec gunicorn
```

### Variables d'Environnement Production

```bash
export DASH_ENV=production
export BEDROCK_MODEL_ID=anthropic.claude-3-5-sonnet-20241022-v2:0
export MAX_WORKERS=100  # Augmenter pour production
```

---

## ğŸ› Troubleshooting

### Erreur: "Bedrock not available"

**Solution**:
```bash
# VÃ©rifier credentials AWS
aws sts get-caller-identity

# VÃ©rifier accÃ¨s Bedrock
aws bedrock list-foundation-models --region us-west-2
```

### Erreur: "Company data not found"

**Solution**:
```bash
# VÃ©rifier que les fichiers JSON existent
ls data/processed/company_10k_data*.json

# Mettre Ã  jour les chemins dans .env
```

### Dashboard ne charge pas

**Solution**:
```bash
# RÃ©installer les dÃ©pendances
pip install -r dashboard/requirements.txt --force-reinstall

# VÃ©rifier le port
lsof -i :8050
```

---

## ğŸ“ˆ Performances

### Temps de Traitement

| OpÃ©ration | Temps Moyen |
|-----------|-------------|
| Upload + Parsing (1 doc) | 0.5s |
| Analyse Bedrock (1 entreprise) | 2.3s |
| Analyse complÃ¨te (500 entreprises) | 4-5 min |
| GÃ©nÃ©ration visualisations | 0.8s |

### Optimisations

- **ParallÃ©lisme**: 50 threads simultanÃ©s
- **Cache**: Scores prÃ©-calculÃ©s pour documents connus
- **Lazy loading**: Chargement progressif des donnÃ©es

---

## ğŸ¤ Contribution

Ce projet a Ã©tÃ© dÃ©veloppÃ© dans le cadre du **Datathon PolyFinances 2025**.

### Ã‰quipe 25

DÃ©veloppeurs passionnÃ©s par l'intersection entre **Finance**, **RÃ©glementation** et **IA**.

### Remerciements

- **AWS** pour l'accÃ¨s Ã  Bedrock
- **Anthropic** pour Claude Sonnet
- **PolyFinances** pour l'organisation du Datathon
- **SEC EDGAR** pour les donnÃ©es 10-K

---

## ğŸ“„ Licence

Projet acadÃ©mique - Datathon PolyFinances 2025

---

## ğŸ“ Support

Pour toute question sur le projet:
- Consulter la documentation dans `/notebooks`
- VÃ©rifier les commentaires dans le code source
- Revoir les exemples dans les notebooks Jupyter

---

## ğŸ”® AmÃ©liorations Futures

- [ ] Support de formats additionnels (DOCX, RTF)
- [ ] Analyse comparative multi-rÃ©gulations
- [ ] SystÃ¨me de recommandations stratÃ©giques
- [ ] API REST pour intÃ©gration externe
- [ ] Cache Redis pour optimisation
- [ ] Tests unitaires complets
- [ ] Documentation API dÃ©taillÃ©e
- [ ] Support multi-utilisateurs
- [ ] Historique d'analyses
- [ ] Alertes temps rÃ©el

---

**Powered by AWS Bedrock & Claude Sonnet 3.5** ğŸš€
